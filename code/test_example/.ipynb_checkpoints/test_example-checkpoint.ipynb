{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we need to start with a top level string \n",
    "- do some edit operations to get bottom level\n",
    "- have each bottom level type index a 3-state hmm\n",
    "- for each 3 state hmm\n",
    "\t- sample some transitions etc \n",
    "\t- have each state index a GMM\n",
    "\t- each GMM generate a 2-dimensional vector \n",
    "    \n",
    "- input: top level string\n",
    "- parameters we need to specify: \n",
    "\t- edit operation parameters\n",
    "\t\t- ins_top (1)\n",
    "\t\t- ins_bot (n)\n",
    "\t\t- sub (n) \n",
    "\t- hmm \n",
    "\t\t- initial (3)\n",
    "\t\t- transition (3x3)\n",
    "\t\t- emission (3xm)\n",
    "    - GMM\n",
    "\t\t- num of components \n",
    "\t\t- mean, variance for each component \n",
    "\t\t- mixture proportions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for simplicity, let's make all top level strings 10 characters long.\n",
    "let's have a 4 character alphabet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_alphabet = [0,1,2,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " let's have 1 more bottom level PLU\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_alphabet = [0,1,2,3,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get some random sequences of top letters that represent a top alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_strings = np.random.choice(top_alphabet, (100, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define prob distributions over ins, sub, del, and sample edit operations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00460564  0.00115141  0.00230282  0.00115141  0.00921128  0.00460564\n",
      "  0.2302821   0.00690846  0.00921128  0.00230282  0.00115141  0.2302821\n",
      "  0.00460564  0.00460564  0.00460564  0.00172712  0.2302821   0.00690846\n",
      "  0.00690846  0.00460564  0.00230282  0.2302821 ]\n"
     ]
    }
   ],
   "source": [
    "ins_top = [2]\n",
    "ins_bot = [.5,1,.5,4,2]\n",
    "sub = [[100, 3, 4, 1],\n",
    "      [.5, 100, 2, 2],\n",
    "      [2, .75, 100, 3],\n",
    "      [3,2,1,100]]\n",
    "\n",
    "\n",
    "full_dir = np.array(ins_top + ins_bot + sub[0] + sub[1] + sub[2] + sub[3], dtype=np.float64)\n",
    "# normalize \n",
    "full_dir = full_dir/np.sum(full_dir)\n",
    "print(full_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_strings = []\n",
    "i = 0\n",
    "while i < len(top_strings):\n",
    "    ts = top_strings[i]\n",
    "    j = 0\n",
    "    bs = []\n",
    "    while j < len(ts):\n",
    "#         sample some edit operation\n",
    "        eo = np.argmax(np.random.multinomial(1, full_dir))\n",
    "        if eo == 0:\n",
    "#             insert top, do nothing\n",
    "            j+=1\n",
    "        elif eo >= 1 and eo <= 5:\n",
    "            bc = bot_alphabet[eo-1]\n",
    "            bs.append(bc)\n",
    "            continue\n",
    "        else:\n",
    "#             sub\n",
    "            bc = bot_alphabet[(eo-5)%4] \n",
    "            bs.append(bc)\n",
    "            j+=1\n",
    "    i+=1\n",
    "    bottom_strings.append(bs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the HMM/GMM parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = [1/3, 1/3, 1/3]\n",
    "transition = [[.5, .5, 0],\n",
    "             [0, .5, .5],\n",
    "             [.75, 0, .25]]\n",
    "\n",
    "components = [[.7,.3],\n",
    "             [.9,.1],\n",
    "             [.3,.7]]\n",
    "\n",
    "n1 = [[0,0], [[1,0],[0,1]]]\n",
    "n2 = [[10, 10], [[1,0],[0,1]]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41, 2)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "def sample_HMMGMM(bs):\n",
    "    mfccs = []\n",
    "    for i, char in enumerate(bs):\n",
    "        vec = None\n",
    "#         if i%10 == 0:\n",
    "#             print(\"done with \", i)\n",
    "        start_state = np.random.choice([0,1,2], p=init)\n",
    "        curr_state = start_state\n",
    "#       get the mfcc vector and transition\n",
    "        while True:\n",
    "            vec = components[curr_state][0]*np.random.multivariate_normal(*n1) + \\\n",
    "                    components[curr_state][1]*np.random.multivariate_normal(*n2)\n",
    "            \n",
    "            mfccs.append(vec)\n",
    "            new_curr_state = np.random.choice([0,1,2], p=transition[curr_state])\n",
    "            if curr_state == 2 and new_curr_state == 0:\n",
    "                break\n",
    "    #         get the mfcc vector and transition\n",
    "            curr_state = new_curr_state\n",
    "    return np.array(mfccs)\n",
    "\n",
    "all_data = []\n",
    "for i, bs in enumerate(bottom_strings):\n",
    "    mfccs = sample_HMMGMM(bs)\n",
    "    all_data.append(mfccs)\n",
    "\n",
    "all_data = np.array(all_data)\n",
    "print(all_data[0].shape)\n",
    "print(all_data.shape)\n",
    "        \n",
    "# for i,line in enumerate(all_data):\n",
    "#     with open(\"/Users/esteng/ULD/audio/example_2d/sent_{}.fea\", \"w\") as f1:\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(285, 39)\n"
     ]
    }
   ],
   "source": [
    "import amdtk\n",
    "data = amdtk.read_htk(\"/Users/esteng/ULD/audio/icicles/icicles.fea\")\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data_stats(data):\n",
    "    \"\"\"Job to collect the statistics.\"\"\"\n",
    "    # We  re-import this module here because this code will run\n",
    "    # remotely.\n",
    "    \n",
    "    stats_0 = data.shape[0]\n",
    "    stats_1 = data.sum(axis=0)\n",
    "    stats_2 = (data**2).sum(axis=0)\n",
    "    retval = (\n",
    "        stats_0,\n",
    "        stats_1,\n",
    "        stats_2\n",
    "    )\n",
    "    return retval\n",
    "\n",
    "data_stats = list(map(collect_data_stats, all_data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def accumulate_stats(data_stats):\n",
    "    n_frames = data_stats[0][0]\n",
    "    mean = data_stats[0][1]\n",
    "    var = data_stats[0][2]\n",
    "    for stats_0, stats_1, stats_2 in data_stats[1:]:\n",
    "        n_frames += stats_0\n",
    "        mean += stats_1\n",
    "        var += stats_2\n",
    "    mean /= n_frames\n",
    "    var = (var / n_frames) - mean**2\n",
    "\n",
    "    data_stats = {\n",
    "        'count': n_frames,\n",
    "        'mean': mean,\n",
    "        'var': var\n",
    "    }\n",
    "    return data_stats\n",
    "\n",
    "final_data_stats = accumulate_stats(data_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "num_tops = 4\n",
    "\n",
    "print(\"starting engines\")\n",
    "subprocess.Popen(['ipcluster', 'start',' --profile', 'default',' -n', '4', '--daemonize'])\n",
    "subprocess.Popen(['sleep', '10']).communicate()\n",
    "\n",
    "\n",
    "rc = Client(profile='default')\n",
    "rc.debug = DEBUG\n",
    "dview = rc[:]\n",
    "print('Connected to', len(dview), 'jobs.')\n",
    "\n",
    "\n",
    "elbo = []\n",
    "time = []\n",
    "def callback(args):\n",
    "    elbo.append(args['objective'])\n",
    "    time.append(args['time'])\n",
    "    print('elbo=' + str(elbo[-1]), 'time=' + str(time[-1]))\n",
    " \n",
    "\n",
    "print(\"Creating phone loop model...\")\n",
    "conc = 0.1\n",
    "\n",
    "\n",
    "\n",
    "model = amdtk.PhoneLoopNoisyChannel.create(\n",
    "    n_units=5,  # number of acoustic units\n",
    "    n_states=3,   # number of states per unit\n",
    "    n_comp_per_state=3,   # number of Gaussians per emission\n",
    "    n_top_units=num_tops, # size of top PLU alphabet\n",
    "    mean=np.zeros_like(final_data_stats['mean']), \n",
    "    var=np.ones_like(final_data_stats['var']),\n",
    "    max_slip_factor=.05\n",
    "    #concentration=conc\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Creating VB optimizer...\")   \n",
    "optimizer = amdtk.NoisyChannelOptimizer(\n",
    "    dview, \n",
    "    final_data_stats, \n",
    "    args= {'epochs': 4,\n",
    "     'batch_size': 1,\n",
    "     'lrate': 0.01,\n",
    "     'pkl_path': \"example_test/\",\n",
    "     'log_dir': 'logs'},\n",
    "    model=model,\n",
    "\n",
    ")\n",
    "\n",
    "print(\"Running VB optimization...\")\n",
    "begin = systime.time()\n",
    "print(\"running with {} paths\".format(len(list(zipped_paths))))\n",
    "optimizer.run(zipped_paths, callback)\n",
    "end = systime.time()\n",
    "print(\"VB optimization took \",end-begin,\" seconds.\")\n",
    "\n",
    "# fig1 = figure(\n",
    "#     x_axis_label='time (s)', \n",
    "#     y_axis_label='ELBO',\n",
    "#     width=400, \n",
    "#     height=400\n",
    "# )\n",
    "# x = np.arange(0, len(elbo), 1)\n",
    "# fig1.line(x, elbo)\n",
    "#show(fig1)\n",
    "\n",
    "print(\"\\nDECODING\\n\")\n",
    "\n",
    "date_string = systime.strftime(\"textgrids_%Y-%m-%d_%H:%M\")\n",
    "\n",
    "# Need to change this according to \n",
    "samples_per_sec = 100\n",
    "\n",
    "\n",
    "for (fea_path, top_path) in zipped_paths:\n",
    "\n",
    "\n",
    "\n",
    "    data = amdtk.read_htk(fea_path)\n",
    "\n",
    "    # Normalize the data\n",
    "    data_mean = np.mean(data)\n",
    "    data_var = np.var(data)\n",
    "    data = (data-data_mean)/np.sqrt(data_var)\n",
    "\n",
    "    # Read top PLU sequence from file\n",
    "    with open(top_path, 'r') as f:\n",
    "        topstring = f.read()\n",
    "        tops = topstring.strip().split(',')\n",
    "        tops = [int(x) for x in tops]\n",
    "\n",
    "    #result = model.decode(data, tops, state_path=False)\n",
    "    #result_path = model.decode(data, tops, state_path=True)\n",
    "    (result_intervals, edit_path) = model.decode(data, tops, phone_intervals=True, edit_ops=True)\n",
    "\n",
    "    print(\"---\")\n",
    "    print(\"Phone sequence for file\", fea_path, \":\")\n",
    "    print(result_intervals)\n",
    "    print(edit_path)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
